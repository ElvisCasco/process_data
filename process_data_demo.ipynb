{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4780f041",
   "metadata": {},
   "source": [
    "# process_data package demo\n",
    "This notebook imports the local package and tests all functions on a small sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49dd120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_data version: unknown\n",
      "exports: ['BMICalculator', 'CSVDataLoader', 'DataPreprocessor', 'DiabetesModel', 'EthnicityEncoder', 'GenderBinaryEncoder', 'data', 'features', 'model']\n"
     ]
    }
   ],
   "source": [
    "# Import the package (add src to sys.path if not installed)\n",
    "from pathlib import Path\n",
    "import sys\n",
    "try:\n",
    "    import process_data as pdlib\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(str(Path.cwd() / \"src\"))\n",
    "    import process_data as pdlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "print(\"process_data version:\", getattr(pdlib, \"__version__\", \"unknown\"))\n",
    "print(\"exports:\", [n for n in dir(pdlib) if not n.startswith(\"_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23392605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sample CSV: c:\\EC\\BSE\\DSDM\\Term 1\\21DM004 Computing for Data Science\\hw4\\process_data\\data\\sample_diabetes_mellitus_data.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'process_data' has no attribute 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m csv_path.exists():\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFound existing sample CSV:\u001b[39m\u001b[33m\"\u001b[39m, csv_path)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     df = \u001b[43mpdlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_loader\u001b[49m(csv_path)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     10\u001b[39m     rng = np.random.default_rng(\u001b[32m42\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'process_data' has no attribute 'data_loader'"
     ]
    }
   ],
   "source": [
    "# Prepare a sample CSV (use existing one if present)\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "csv_path = data_dir / \"sample_diabetes_mellitus_data.csv\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if csv_path.exists():\n",
    "    print(\"Found existing sample CSV:\", csv_path)\n",
    "    df = pdlib.data_loader(csv_path)\n",
    "else:\n",
    "    rng = np.random.default_rng(42)\n",
    "    n = 50\n",
    "    df = pd.DataFrame({\n",
    "        \"age\": rng.integers(18, 85, size=n).astype(float),\n",
    "        \"height\": rng.normal(170, 10, size=n),\n",
    "        \"weight\": rng.normal(75, 15, size=n),\n",
    "        \"aids\": rng.integers(0, 2, size=n),\n",
    "        \"cirrhosis\": rng.integers(0, 2, size=n),\n",
    "        \"hepatic_failure\": rng.integers(0, 2, size=n),\n",
    "        \"immunosuppression\": rng.integers(0, 2, size=n),\n",
    "        \"leukemia\": rng.integers(0, 2, size=n),\n",
    "        \"lymphoma\": rng.integers(0, 2, size=n),\n",
    "        \"solid_tumor_with_metastasis\": rng.integers(0, 2, size=n),\n",
    "        \"gender\": rng.choice([\"M\", \"F\", \"Male\", \"Female\", None], size=n, p=[0.35,0.35,0.1,0.1,0.1]),\n",
    "        \"ethnicity\": rng.choice([\"A\",\"B\",\"C\", None], size=n, p=[0.4,0.35,0.2,0.05]),\n",
    "        \"diabetes_mellitus\": rng.integers(0, 2, size=n)\n",
    "    })\n",
    "    df.loc[[1, 7], \"age\"] = np.nan\n",
    "    df.loc[[2, 9], \"gender\"] = None\n",
    "    df.loc[[3], \"ethnicity\"] = None\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Created sample CSV:\", csv_path)\n",
    "    print(df.head())\n",
    "\n",
    "print(\"Data shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data_loader and data_split\n",
    "df_loaded = pdlib.data_loader(csv_path)\n",
    "train_df, test_df = pdlib.data_split(csv_path, test_size=0.3, random_state=42)\n",
    "print(\"Loaded:\", df_loaded.shape, \"Train:\", train_df.shape, \"Test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaNs in specific columns (age, gender, ethnicity)\n",
    "cols_nan = [\"age\", \"gender\", \"ethnicity\"]\n",
    "train_df = pdlib.data_remove_nans(train_df, columns=cols_nan)\n",
    "test_df = pdlib.data_remove_nans(test_df, columns=cols_nan)\n",
    "print(\"After remove_nans -> Train/Test:\", train_df.shape, test_df.shape)\n",
    "assert train_df[cols_nan].isna().sum().sum() == 0\n",
    "assert test_df[cols_nan].isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs in numeric columns height, weight with means\n",
    "train_df = pdlib.data_fill_nans(train_df, columns=[\"height\", \"weight\"])\n",
    "test_df = pdlib.data_fill_nans(test_df, columns=[\"height\", \"weight\"])\n",
    "print(\"Height/Weight NaNs after fill -> Train/Test:\",\n",
    "      train_df[[\"height\",\"weight\"]].isna().sum().to_dict(),\n",
    "      test_df[[\"height\",\"weight\"]].isna().sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aab607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode ethnicity and make gender binary\n",
    "train_df = pdlib.data_encoding(train_df, columns=[\"ethnicity\"])\n",
    "test_df = pdlib.data_encoding(test_df, columns=[\"ethnicity\"])\n",
    "train_df = pdlib.data_binary(train_df, column=\"gender\")\n",
    "test_df = pdlib.data_binary(test_df, column=\"gender\")\n",
    "print(\"After encoding/binary -> Train/Test:\", train_df.shape, test_df.shape)\n",
    "print(\"gender dtype:\", train_df[\"gender\"].dtype)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9031931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target for model training\n",
    "FEATURES = [\n",
    "    \"age\", \"height\", \"weight\",\n",
    "    \"aids\", \"cirrhosis\", \"hepatic_failure\",\n",
    "    \"immunosuppression\", \"leukemia\", \"lymphoma\",\n",
    "    \"solid_tumor_with_metastasis\",\n",
    "]\n",
    "TARGET = \"diabetes_mellitus\"\n",
    "\n",
    "missing_tr = [c for c in FEATURES if c not in train_df.columns]\n",
    "missing_te = [c for c in FEATURES if c not in test_df.columns]\n",
    "if missing_tr or missing_te:\n",
    "    raise KeyError(f\"Missing required features. Train: {missing_tr}, Test: {missing_te}\")\n",
    "\n",
    "# Train models\n",
    "X_train = train_df[FEATURES]\n",
    "y_train = train_df[TARGET]\n",
    "model_lr = pdlib.data_train_models(X_train, y_train, model_type=\"logreg\")\n",
    "model_rf = pdlib.data_train_models(X_train, y_train, model_type=\"rf\")\n",
    "\n",
    "print(type(model_lr).__name__, type(model_rf).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prediction probabilities\n",
    "try:\n",
    "    add_predictions = pdlib.add_predictions\n",
    "except AttributeError:\n",
    "    from process_data.pred_auc_score import add_predictions\n",
    "\n",
    "train_with_pred, test_with_pred = add_predictions(\n",
    "    model_lr, train_df, test_df, FEATURES, pred_col=\"predictions\", inplace=False\n",
    ")\n",
    "print(train_with_pred[[TARGET, \"predictions\"]].head())\n",
    "print(test_with_pred[[TARGET, \"predictions\"]].head())\n",
    "assert \"predictions\" in train_with_pred.columns and \"predictions\" in test_with_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC AUC\n",
    "auc_train = pdlib.pred_auc_score(train_with_pred[TARGET], train_with_pred[\"predictions\"]) \n",
    "auc_test = pdlib.pred_auc_score(test_with_pred[TARGET], test_with_pred[\"predictions\"]) \n",
    "print(f\"AUC (train): {auc_train:.3f} | AUC (test): {auc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51009a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data_predict matches add_predictions\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "proba_chk = pdlib.data_predict(model_lr, test_df[FEATURES], proba=True)\n",
    "assert_allclose(proba_chk, test_with_pred[\"predictions\"].to_numpy(), atol=1e-9)\n",
    "print(\"data_predict(proba=True) matches add_predictions output on test set.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
