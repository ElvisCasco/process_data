{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9NZlKovcXY5"
      },
      "source": [
        "[GitHub source](https://github.com/ElvisCasco/process_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_KwreGVc0U9",
        "outputId": "59733eb9-0885-4bda-e290-37e1b8ed39d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#wd = '/content/drive/MyDrive/DSDM/Term_1/21DM004 Computing for Data Science/hw4/'\n",
        "# from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rt4XV4acBNK",
        "outputId": "c847d555-39a5-4f17-f43f-7aeaf954d2f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ElvisCasco/process_data.git\n",
            "  Cloning https://github.com/ElvisCasco/process_data.git to c:\\users\\majoa\\appdata\\local\\temp\\pip-req-build-61erbojw\n",
            "  Resolved https://github.com/ElvisCasco/process_data.git to commit b0ff22800218285f6d850dc9264d125940f755b3\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Building wheels for collected packages: process_data\n",
            "  Building wheel for process_data (pyproject.toml): started\n",
            "  Building wheel for process_data (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for process_data: filename=process_data-0.1.0-py3-none-any.whl size=8637 sha256=de0d9e9e4cf64462ca523789f0b6271d20678e580141b7246ca48425e8a79f2a\n",
            "  Stored in directory: C:\\Users\\majoa\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-g0b274cs\\wheels\\bc\\36\\de\\23864e163eba71b8f07e6db77cc823f7f1b51d90aff8a6d687\n",
            "Successfully built process_data\n",
            "Installing collected packages: process_data\n",
            "  Attempting uninstall: process_data\n",
            "    Found existing installation: process_data 0.1.0\n",
            "    Uninstalling process_data-0.1.0:\n",
            "      Successfully uninstalled process_data-0.1.0\n",
            "Successfully installed process_data-0.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/ElvisCasco/process_data.git 'C:\\Users\\majoa\\AppData\\Local\\Temp\\pip-req-build-61erbojw'\n"
          ]
        }
      ],
      "source": [
        "!pip install --no-deps git+https://github.com/ElvisCasco/process_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.11.13 (main, Sep  2 2025, 14:14:37) [MSC v.1944 64 bit (AMD64)]\n",
            "c:\\Users\\majoa\\OneDrive\\Desktop\\Learning\\Grad School\\computing_data_science\\hw6\\process_data\\.venv\\Scripts\\python.exe\n",
            "Windows-10-10.0.26200-SP0\n"
          ]
        }
      ],
      "source": [
        "import sys, platform\n",
        "print(sys.version)\n",
        "print(sys.executable)\n",
        "print(platform.platform())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHl4g7MHcVlP",
        "outputId": "e92abfb9-cbb2-4f81-f00d-0f9d94b3e4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "process_data package - Installed from GitHub\n",
            "============================================================\n",
            "Version: 0.1.0\n",
            "Location: c:\\Users\\majoa\\OneDrive\\Desktop\\Learning\\Grad School\\computing_data_science\\hw6\\process_data\\.venv\\Lib\\site-packages\\process_data\\__init__.py\n",
            "\n",
            "Available functions:\n",
            "  1. data_binary\n",
            "  2. data_encoding\n",
            "  3. data_fill_nans\n",
            "  4. data_loader\n",
            "  5. data_predict\n",
            "  6. data_remove_nans\n",
            "  7. data_split\n",
            "  8. data_train_models\n",
            "  9. pred_auc_score\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import the package (installed from GitHub)\n",
        "import process_data as pdlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import inspect\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"process_data package - Installed from GitHub\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Version: {getattr(pdlib, '__version__', 'unknown')}\")\n",
        "print(f\"Location: {pdlib.__file__}\")\n",
        "print(f\"\\nAvailable functions:\")\n",
        "exports = [n for n in dir(pdlib) if not n.startswith(\"_\")]\n",
        "for i, func in enumerate(exports, 1):\n",
        "    print(f\"  {i}. {func}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_Q76hzeIiF"
      },
      "source": [
        "## a. Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJkYuixbhNRp"
      },
      "source": [
        "a. Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSOtIEudhu1",
        "outputId": "ba28e271-52de-435c-ea2f-58e2402b4d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully. Shape: (10000, 53)\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Prepare a sample CSV\n",
        "csv_path = \"data/sample_diabetes_mellitus_data.csv\"\n",
        "df = pdlib.data_loader(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1njbDQPeGCN"
      },
      "source": [
        "## b. Test data_loader and data_split:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf4eL7rAhTof"
      },
      "source": [
        "b. Split the data between train and test. (you can use train_test_split from sklearn or any other way)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4NX-5CeSDd",
        "outputId": "62ab853f-5842-40d2-e979-620589c7aa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 1: data_loader and data_split\n",
            "============================================================\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "‚úÖ data_loader: Loaded (10000, 53)\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "‚úÖ data_split:\n",
            "   Train: (7000, 53) (70.0%)\n",
            "   Test: (3000, 53) (30.0%)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Test data_loader and data_split\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 1: data_loader and data_split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df_loaded = pdlib.data_loader(csv_path)\n",
        "print(f\"‚úÖ data_loader: Loaded {df_loaded.shape}\")\n",
        "\n",
        "train_df, test_df = pdlib.data_split(csv_path, test_size=0.3, random_state=42)\n",
        "print(f\"‚úÖ data_split:\")\n",
        "print(f\"   Train: {train_df.shape} ({train_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")\n",
        "print(f\"   Test: {test_df.shape} ({test_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUoWutD5ec-T"
      },
      "source": [
        "## c. Test data_remove_nans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSRnFLzLhaaE"
      },
      "source": [
        "c. Remove those rows that contain NaN values in the columns: age, gender, ethnicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr_z1wjefrz",
        "outputId": "33480988-276b-4061-e326-5b38425fe504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 2: data_remove_nans\n",
            "============================================================\n",
            "Before: Train (7000, 53), NaNs=465\n",
            "        Test (3000, 53), NaNs=185\n",
            "After:  Train (6547, 53), NaNs=0\n",
            "        Test (2821, 53), NaNs=0\n",
            "‚úÖ Passed: No NaNs in specified columns\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Test data_remove_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 2: data_remove_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_nan = [\"age\", \"gender\", \"ethnicity\"]\n",
        "print(f\"Before: Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "\n",
        "train_df = pdlib.data_remove_nans(train_df, columns=cols_nan)\n",
        "test_df = pdlib.data_remove_nans(test_df, columns=cols_nan)\n",
        "\n",
        "print(f\"After:  Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "print(\"‚úÖ Passed: No NaNs in specified columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFnW6IHceptX"
      },
      "source": [
        "## d. Test data_fill_nans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAsmeoMzhhWU"
      },
      "source": [
        "d. Fill NaN with the mean value of the column in the columns: height, weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7p-jYjZetVg",
        "outputId": "41cdb3ec-28a0-44c5-f463-55da084057df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 3: data_fill_nans\n",
            "============================================================\n",
            "Before: {'height': 86, 'weight': 1077}\n",
            "After:  {'height': 0, 'weight': 0}\n",
            "‚úÖ Mean height: 169.98, weight: 86.91\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Test data_fill_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 3: data_fill_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_fill = [\"height\", \"weight\"]\n",
        "print(f\"Before: {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "\n",
        "train_df = pdlib.data_fill_nans(train_df, columns=cols_fill)\n",
        "test_df = pdlib.data_fill_nans(test_df, columns=cols_fill)\n",
        "\n",
        "print(f\"After:  {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "print(f\"‚úÖ Mean height: {train_df['height'].mean():.2f}, weight: {train_df['weight'].mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-at5k0K-e3SB"
      },
      "source": [
        "## e. Test data_encoding:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gb-yvGFhrmq"
      },
      "source": [
        "e. Generate dummies for ethnicity column (One hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLbr2QZe6RF",
        "outputId": "a72d1e9a-7161-4e74-ebf5-190b01116a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 4: data_encoding\n",
            "============================================================\n",
            "Before: 53 columns\n",
            "After:  58 columns\n",
            "‚úÖ New columns: ['ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Test data_encoding (one-hot encoding)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 4: data_encoding\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: {train_df.shape[1]} columns\")\n",
        "train_df = pdlib.data_encoding(train_df, columns=[\"ethnicity\"])\n",
        "test_df = pdlib.data_encoding(test_df, columns=[\"ethnicity\"])\n",
        "\n",
        "ethnicity_cols = [c for c in train_df.columns if c.startswith(\"ethnicity_\")]\n",
        "print(f\"After:  {train_df.shape[1]} columns\")\n",
        "print(f\"‚úÖ New columns: {ethnicity_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABOWSYs1fFuS"
      },
      "source": [
        "## f. Test data_binary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnB3t2Hfhxw5"
      },
      "source": [
        "f. Create a binary variable for gender M/F."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LsAHrtfIcN",
        "outputId": "08d6d92e-dc50-4ed7-d219-1197f788d777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 5: data_binary\n",
            "============================================================\n",
            "Before: gender dtype=object, unique=['F' 'M']\n",
            "After:  gender dtype=Int64, unique=[np.int64(0), np.int64(1)]\n",
            "‚úÖ Value counts:\n",
            "gender\n",
            "1    3599\n",
            "0    2948\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Test data_binary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 5: data_binary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: gender dtype={train_df['gender'].dtype}, unique={train_df['gender'].unique()}\")\n",
        "train_df = pdlib.data_binary(train_df, column=\"gender\")\n",
        "test_df = pdlib.data_binary(test_df, column=\"gender\")\n",
        "\n",
        "print(f\"After:  gender dtype={train_df['gender'].dtype}, unique={sorted(train_df['gender'].dropna().unique())}\")\n",
        "print(f\"‚úÖ Value counts:\\n{train_df['gender'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR9Uw4GXf2la"
      },
      "source": [
        "## g. Test data_train_models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXPmlHuHiA7E"
      },
      "source": [
        "g. Train a model (for instance LogisticRegression or RandomForestClassifier from sklearn) in the train data.\n",
        "\n",
        "Use as features the columns: `age`, `height`, `weight`, `aids`, `cirrhosis`, `hepatic_failure`, `immunosuppression`, `leukemia`, `lymphoma`, `solid_tumor_with_metastasis`.\n",
        "\n",
        "Use as target the column: `diabetes_mellitus`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92JAivSXf50G",
        "outputId": "21aec3f0-2a7b-412b-92b9-dffd090206c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 6: data_train_models\n",
            "============================================================\n",
            "Training with 10 features, 6547 samples\n",
            "‚úÖ Trained: LogisticRegression\n",
            "‚úÖ Trained: RandomForestClassifier\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Train models\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 6: data_train_models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "FEATURES = [\n",
        "    \"age\", \"height\", \"weight\",\n",
        "    \"aids\", \"cirrhosis\", \"hepatic_failure\",\n",
        "    \"immunosuppression\", \"leukemia\", \"lymphoma\",\n",
        "    \"solid_tumor_with_metastasis\",\n",
        "]\n",
        "TARGET = \"diabetes_mellitus\"\n",
        "\n",
        "X_train = train_df[FEATURES]\n",
        "y_train = train_df[TARGET]\n",
        "\n",
        "print(f\"Training with {len(FEATURES)} features, {len(X_train)} samples\")\n",
        "model_lr = pdlib.data_train_models(X_train, y_train, model_type=\"logreg\")\n",
        "model_rf = pdlib.data_train_models(X_train, y_train, model_type=\"rf\")\n",
        "\n",
        "print(f\"‚úÖ Trained: {type(model_lr).__name__}\")\n",
        "print(f\"‚úÖ Trained: {type(model_rf).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBDdiKUDgI9f"
      },
      "source": [
        "## h. Test add_predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C3kzsGhieiv"
      },
      "source": [
        "h. Predict the targets for both the train and test sets and add the prediction as a new column (use predict_proba from the model to get the predicted probabilities) name the new column something\n",
        "like predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiOkg5HvgLXg",
        "outputId": "34c37954-db6e-42d5-bcde-6101acccdcbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 7: add_predictions\n",
            "============================================================\n",
            "‚úÖ Added 'predictions' column to train and test sets\n",
            "\n",
            "üìä Train predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "9069                  0     0.133019\n",
            "2603                  0     0.235128\n",
            "7738                  0     0.305615\n",
            "1579                  0     0.168840\n",
            "5058                  0     0.156941\n",
            "\n",
            "üìä Test predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "6252                  1     0.317018\n",
            "1731                  0     0.282180\n",
            "4742                  0     0.117651\n",
            "4521                  0     0.130718\n",
            "6340                  1     0.331449\n",
            "\n",
            "‚úÖ Assertion passed\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Add predictions to train and test sets\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 7: add_predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Import add_predictions function\n",
        "try:\n",
        "    add_predictions = pdlib.add_predictions\n",
        "except AttributeError:\n",
        "    from process_data.pred_auc_score import add_predictions\n",
        "\n",
        "# Add predictions using LogisticRegression model\n",
        "train_with_pred, test_with_pred = add_predictions(\n",
        "    model_lr,\n",
        "    train_df,\n",
        "    test_df,\n",
        "    FEATURES,\n",
        "    pred_col=\"predictions\",\n",
        "    inplace=False\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Added 'predictions' column to train and test sets\")\n",
        "print(f\"\\nüìä Train predictions sample:\")\n",
        "print(train_with_pred[[TARGET, \"predictions\"]].head())\n",
        "print(f\"\\nüìä Test predictions sample:\")\n",
        "print(test_with_pred[[TARGET, \"predictions\"]].head())\n",
        "\n",
        "assert \"predictions\" in train_with_pred.columns\n",
        "assert \"predictions\" in test_with_pred.columns\n",
        "print(\"\\n‚úÖ Assertion passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuwl2aG6gYNt"
      },
      "source": [
        "## i. Test pred_auc_score:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaLl0bpHi4SD"
      },
      "source": [
        "i. Compute the train and test roc_auc metric using roc_auc_score from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJSvN4dgbA8",
        "outputId": "2843827f-e774-40e4-85b3-274f6d3b5d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 8: pred_auc_score (ROC AUC)\n",
            "============================================================\n",
            "‚úÖ ROC AUC (LogisticRegression):\n",
            "   Train AUC: 0.6761\n",
            "   Test AUC:  0.6559\n",
            "   Difference: 0.0202\n",
            "‚úÖ Model performs better than random\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Compute ROC AUC scores\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 8: pred_auc_score (ROC AUC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "auc_train = pdlib.pred_auc_score(\n",
        "    train_with_pred[TARGET],\n",
        "    train_with_pred[\"predictions\"]\n",
        ")\n",
        "auc_test = pdlib.pred_auc_score(\n",
        "    test_with_pred[TARGET],\n",
        "    test_with_pred[\"predictions\"]\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ ROC AUC (LogisticRegression):\")\n",
        "print(f\"   Train AUC: {auc_train:.4f}\")\n",
        "print(f\"   Test AUC:  {auc_test:.4f}\")\n",
        "print(f\"   Difference: {abs(auc_train - auc_test):.4f}\")\n",
        "\n",
        "if auc_test > 0.5:\n",
        "    print(f\"‚úÖ Model performs better than random\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Model needs improvement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBFTrRj4gldm"
      },
      "source": [
        "## Test data_predict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzX-AnDygoGW",
        "outputId": "f224bf4c-3d3f-4c00-8336-90d3590a8546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 9: data_predict\n",
            "============================================================\n",
            "‚úÖ Probabilities shape: (2821,)\n",
            "   Sample: [0.31701752 0.28218009 0.1176509  0.13071842 0.33144866]\n",
            "‚úÖ data_predict matches add_predictions\n",
            "‚úÖ Class predictions: [0 0 0 0 0 0 0 0 0 0]\n",
            "   Unique classes: [np.int64(0), np.int64(1)]\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Test data_predict function\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 9: data_predict\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "# Test predict_proba\n",
        "proba_test = pdlib.data_predict(model_lr, test_df[FEATURES], proba=True)\n",
        "print(f\"‚úÖ Probabilities shape: {proba_test.shape}\")\n",
        "print(f\"   Sample: {proba_test[:5]}\")\n",
        "\n",
        "# Verify matches add_predictions\n",
        "assert_allclose(proba_test, test_with_pred[\"predictions\"].to_numpy(), atol=1e-9)\n",
        "print(\"‚úÖ data_predict matches add_predictions\")\n",
        "\n",
        "# Test class predictions\n",
        "class_pred = pdlib.data_predict(model_lr, test_df[FEATURES], proba=False)\n",
        "print(f\"‚úÖ Class predictions: {class_pred[:10]}\")\n",
        "print(f\"   Unique classes: {sorted(set(class_pred))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bedC6mFnnZ_A"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkgq75Zxg3ye",
        "outputId": "56af4395-ebb8-410d-cd10-9fdfd23fce3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üéâ ALL TESTS COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "\n",
            "‚úÖ Functions tested:\n",
            "   1. data_loader\n",
            "   2. data_split\n",
            "   3. data_remove_nans\n",
            "   4. data_fill_nans\n",
            "   5. data_encoding\n",
            "   6. data_binary\n",
            "   7. data_train_models\n",
            "   8. add_predictions\n",
            "   9. pred_auc_score\n",
            "  10. data_predict\n",
            "\n",
            "üìä Final Results:\n",
            "  Dataset size: 9368 samples\n",
            "  Train: 6547 samples\n",
            "  Test:  2821 samples\n",
            "  Features: 10\n",
            "  Train AUC: 0.6761\n",
            "  Test AUC:  0.6559\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéâ ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n‚úÖ Functions tested:\")\n",
        "functions_tested = [\n",
        "    \"data_loader\", \"data_split\", \"data_remove_nans\",\n",
        "    \"data_fill_nans\", \"data_encoding\", \"data_binary\",\n",
        "    \"data_train_models\", \"add_predictions\",\n",
        "    \"pred_auc_score\", \"data_predict\"\n",
        "]\n",
        "for i, func in enumerate(functions_tested, 1):\n",
        "    print(f\"  {i:2d}. {func}\")\n",
        "\n",
        "print(f\"\\nüìä Final Results:\")\n",
        "print(f\"  Dataset size: {len(train_with_pred) + len(test_with_pred)} samples\")\n",
        "print(f\"  Train: {len(train_with_pred)} samples\")\n",
        "print(f\"  Test:  {len(test_with_pred)} samples\")\n",
        "print(f\"  Features: {len(FEATURES)}\")\n",
        "print(f\"  Train AUC: {auc_train:.4f}\")\n",
        "print(f\"  Test AUC:  {auc_test:.4f}\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "process-data",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
