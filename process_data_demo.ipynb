{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9NZlKovcXY5"
      },
      "source": [
        "[GitHub source](https://github.com/ElvisCasco/process_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_KwreGVc0U9",
        "outputId": "59733eb9-0885-4bda-e290-37e1b8ed39d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: c:\\EC\\BSE\\DSDM\\Term 1\\21DM004 Computing for Data Science\\hw4\\process_data\\\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#wd = '/content/drive/MyDrive/DSDM/Term_1/21DM004 Computing for Data Science/hw4/'\n",
        "#from PIL import Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "wd = str(Path.cwd()) + \"\\\\\"\n",
        "print(f\"Working directory: {wd}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "git add .\n",
        "git commit -m \"Update package\"\n",
        "git pull origin main\n",
        "git push origin main\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ElvisCasco/process_data.git\n",
            "  Cloning https://github.com/ElvisCasco/process_data.git to c:\\users\\ecasc\\appdata\\local\\temp\\pip-req-build-cjdla6h8\n",
            "  Resolved https://github.com/ElvisCasco/process_data.git to commit abaa442eb2689599ab561ea5942cbf0b22903fcf\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: pandas>=1.3.0 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from process_data==0.1.0) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from process_data==0.1.0) (2.3.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from process_data==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from pandas>=1.3.0->process_data==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from pandas>=1.3.0->process_data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from pandas>=1.3.0->process_data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->process_data==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->process_data==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->process_data==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\ec\\bse\\dsdm\\term 1\\21dm004 computing for data science\\hw4\\process_data\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->process_data==0.1.0) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/ElvisCasco/process_data.git 'C:\\Users\\ecasc\\AppData\\Local\\Temp\\pip-req-build-cjdla6h8'\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/ElvisCasco/process_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHl4g7MHcVlP",
        "outputId": "e92abfb9-cbb2-4f81-f00d-0f9d94b3e4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "process_data package - Installed from GitHub\n",
            "============================================================\n",
            "\n",
            "Available functions:\n",
            "  1. data_binary\n",
            "  2. data_encoding\n",
            "  3. data_fill_nans\n",
            "  4. data_loader\n",
            "  5. data_predict\n",
            "  6. data_remove_nans\n",
            "  7. data_split\n",
            "  8. data_train_models\n",
            "  9. pred_auc_score\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Import the package (installed from GitHub)\n",
        "import process_data as pdlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import inspect\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"process_data package - Installed from GitHub\")\n",
        "print(\"=\" * 60)\n",
        "#print(f\"Version: {getattr(pdlib, '__version__', 'unknown')}\")\n",
        "#print(f\"Location: {pdlib.__file__}\")\n",
        "print(f\"\\nAvailable functions:\")\n",
        "exports = [n for n in dir(pdlib) if not n.startswith(\"_\")]\n",
        "for i, func in enumerate(exports, 1):\n",
        "    print(f\"  {i}. {func}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_Q76hzeIiF"
      },
      "source": [
        "## a. Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJkYuixbhNRp"
      },
      "source": [
        "a. Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSOtIEudhu1",
        "outputId": "ba28e271-52de-435c-ea2f-58e2402b4d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully. Shape: (10000, 53)\n"
          ]
        }
      ],
      "source": [
        "# Import the package (installed from GitHub)\n",
        "import process_data as pdlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import inspect\n",
        "from pathlib import Path\n",
        "\n",
        "# Read the CSV\n",
        "csv_path = wd + \"data/\" + \"sample_diabetes_mellitus_data.csv\"\n",
        "df = pdlib.data_loader(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully. Shape: (10000, 53)\n",
            "Data loaded successfully. Shape: (10000, 53)\n"
          ]
        }
      ],
      "source": [
        "def test_data_loader_with_path_object(csv_path):\n",
        "    \"\"\"Test loading with Path object\"\"\"\n",
        "    csv_path = wd + \"data/\" + \"sample_diabetes_mellitus_data.csv\"\n",
        "    df = pdlib.data_loader(csv_path)\n",
        "    \n",
        "    loaded_df = pdlib.data_loader(csv_path)\n",
        "    assert loaded_df.shape == (10000, 53)\n",
        "\n",
        "test_data_loader_with_path_object(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1njbDQPeGCN"
      },
      "source": [
        "## b. Test data_loader and data_split:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf4eL7rAhTof"
      },
      "source": [
        "b. Split the data between train and test. (you can use train_test_split from sklearn or any other way)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4NX-5CeSDd",
        "outputId": "62ab853f-5842-40d2-e979-620589c7aa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 1: data_loader and data_split\n",
            "============================================================\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "data_loader: Loaded (10000, 53)\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "data_split:\n",
            "   Train: (7000, 53) (70.0%)\n",
            "   Test: (3000, 53) (30.0%)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Test data_loader and data_split\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 1: data_loader and data_split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df_loaded = pdlib.data_loader(csv_path)\n",
        "print(f\"data_loader: Loaded {df_loaded.shape}\")\n",
        "\n",
        "train_df, test_df = pdlib.data_split(csv_path, test_size=0.3, random_state=42)\n",
        "print(f\"data_split:\")\n",
        "print(f\"   Train: {train_df.shape} ({train_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")\n",
        "print(f\"   Test: {test_df.shape} ({test_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUoWutD5ec-T"
      },
      "source": [
        "## c. Test data_remove_nans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSRnFLzLhaaE"
      },
      "source": [
        "c. Remove those rows that contain NaN values in the columns: age, gender, ethnicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr_z1wjefrz",
        "outputId": "33480988-276b-4061-e326-5b38425fe504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 2: data_remove_nans\n",
            "============================================================\n",
            "Before: Train (7000, 53), NaNs=465\n",
            "        Test (3000, 53), NaNs=185\n",
            "After:  Train (6547, 53), NaNs=0\n",
            "        Test (2821, 53), NaNs=0\n",
            "Passed: No NaNs in specified columns\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Test data_remove_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 2: data_remove_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_nan = [\"age\", \"gender\", \"ethnicity\"]\n",
        "print(f\"Before: Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "\n",
        "train_df = pdlib.data_remove_nans(train_df, columns=cols_nan)\n",
        "test_df = pdlib.data_remove_nans(test_df, columns=cols_nan)\n",
        "\n",
        "print(f\"After:  Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "print(\"Passed: No NaNs in specified columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFnW6IHceptX"
      },
      "source": [
        "## d. Test data_fill_nans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAsmeoMzhhWU"
      },
      "source": [
        "d. Fill NaN with the mean value of the column in the columns: height, weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7p-jYjZetVg",
        "outputId": "41cdb3ec-28a0-44c5-f463-55da084057df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 3: data_fill_nans\n",
            "============================================================\n",
            "Before: {'height': 86, 'weight': 1077}\n",
            "After:  {'height': 0, 'weight': 0}\n",
            "Mean height: 169.98, weight: 86.91\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Test data_fill_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 3: data_fill_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_fill = [\"height\", \"weight\"]\n",
        "print(f\"Before: {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "\n",
        "train_df = pdlib.data_fill_nans(train_df, columns=cols_fill)\n",
        "test_df = pdlib.data_fill_nans(test_df, columns=cols_fill)\n",
        "\n",
        "print(f\"After:  {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "print(f\"Mean height: {train_df['height'].mean():.2f}, weight: {train_df['weight'].mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-at5k0K-e3SB"
      },
      "source": [
        "## e. Test data_encoding:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gb-yvGFhrmq"
      },
      "source": [
        "e. Generate dummies for ethnicity column (One hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLbr2QZe6RF",
        "outputId": "a72d1e9a-7161-4e74-ebf5-190b01116a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 4: data_encoding\n",
            "============================================================\n",
            "Before: 53 columns\n",
            "After:  58 columns\n",
            "New columns: ['ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Test data_encoding (one-hot encoding)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 4: data_encoding\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: {train_df.shape[1]} columns\")\n",
        "train_df = pdlib.data_encoding(train_df, columns=[\"ethnicity\"])\n",
        "test_df = pdlib.data_encoding(test_df, columns=[\"ethnicity\"])\n",
        "\n",
        "ethnicity_cols = [c for c in train_df.columns if c.startswith(\"ethnicity_\")]\n",
        "print(f\"After:  {train_df.shape[1]} columns\")\n",
        "print(f\"New columns: {ethnicity_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABOWSYs1fFuS"
      },
      "source": [
        "## f. Test data_binary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnB3t2Hfhxw5"
      },
      "source": [
        "f. Create a binary variable for gender M/F."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LsAHrtfIcN",
        "outputId": "08d6d92e-dc50-4ed7-d219-1197f788d777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 5: data_binary\n",
            "============================================================\n",
            "Before: gender dtype=object, unique=['F' 'M']\n",
            "After:  gender dtype=Int64, unique=[np.int64(0), np.int64(1)]\n",
            "Value counts:\n",
            "gender\n",
            "1    3599\n",
            "0    2948\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Test data_binary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 5: data_binary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: gender dtype={train_df['gender'].dtype}, unique={train_df['gender'].unique()}\")\n",
        "train_df = pdlib.data_binary(train_df, column=\"gender\")\n",
        "test_df = pdlib.data_binary(test_df, column=\"gender\")\n",
        "\n",
        "print(f\"After:  gender dtype={train_df['gender'].dtype}, unique={sorted(train_df['gender'].dropna().unique())}\")\n",
        "print(f\"Value counts:\\n{train_df['gender'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR9Uw4GXf2la"
      },
      "source": [
        "## g. Test data_train_models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXPmlHuHiA7E"
      },
      "source": [
        "g. Train a model (for instance LogisticRegression or RandomForestClassifier from sklearn) in the train data.\n",
        "\n",
        "Use as features the columns: `age`, `height`, `weight`, `aids`, `cirrhosis`, `hepatic_failure`, `immunosuppression`, `leukemia`, `lymphoma`, `solid_tumor_with_metastasis`.\n",
        "\n",
        "Use as target the column: `diabetes_mellitus`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92JAivSXf50G",
        "outputId": "21aec3f0-2a7b-412b-92b9-dffd090206c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 6: data_train_models\n",
            "============================================================\n",
            "Training with 10 features, 6547 samples\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained: LogisticRegression\n",
            "Trained: RandomForestClassifier\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Train models\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 6: data_train_models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "FEATURES = [\n",
        "    \"age\", \"height\", \"weight\",\n",
        "    \"aids\", \"cirrhosis\", \"hepatic_failure\",\n",
        "    \"immunosuppression\", \"leukemia\", \"lymphoma\",\n",
        "    \"solid_tumor_with_metastasis\",\n",
        "]\n",
        "TARGET = \"diabetes_mellitus\"\n",
        "\n",
        "X_train = train_df[FEATURES]\n",
        "y_train = train_df[TARGET]\n",
        "\n",
        "print(f\"Training with {len(FEATURES)} features, {len(X_train)} samples\")\n",
        "model_lr = pdlib.data_train_models(X_train, y_train, model_type=\"logreg\")\n",
        "model_rf = pdlib.data_train_models(X_train, y_train, model_type=\"rf\")\n",
        "\n",
        "print(f\"Trained: {type(model_lr).__name__}\")\n",
        "print(f\"Trained: {type(model_rf).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBDdiKUDgI9f"
      },
      "source": [
        "## h. Test add_predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C3kzsGhieiv"
      },
      "source": [
        "h. Predict the targets for both the train and test sets and add the prediction as a new column (use predict_proba from the model to get the predicted probabilities) name the new column something\n",
        "like predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiOkg5HvgLXg",
        "outputId": "34c37954-db6e-42d5-bcde-6101acccdcbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 7: add_predictions\n",
            "============================================================\n",
            "Added 'predictions' column to train and test sets\n",
            "\n",
            "Train predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "9069                  0     0.133033\n",
            "2603                  0     0.235128\n",
            "7738                  0     0.305614\n",
            "1579                  0     0.168839\n",
            "5058                  0     0.156940\n",
            "\n",
            "Test predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "6252                  1     0.317016\n",
            "1731                  0     0.282181\n",
            "4742                  0     0.117664\n",
            "4521                  0     0.130718\n",
            "6340                  1     0.331450\n",
            "\n",
            "Assertion passed\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Add predictions to train and test sets\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 7: add_predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Import add_predictions function\n",
        "try:\n",
        "    add_predictions = pdlib.add_predictions\n",
        "except AttributeError:\n",
        "    from process_data.pred_auc_score import add_predictions\n",
        "\n",
        "# Add predictions using LogisticRegression model\n",
        "train_with_pred, test_with_pred = add_predictions(\n",
        "    model_lr,\n",
        "    train_df,\n",
        "    test_df,\n",
        "    FEATURES,\n",
        "    pred_col=\"predictions\",\n",
        "    inplace=False\n",
        ")\n",
        "\n",
        "print(f\"Added 'predictions' column to train and test sets\")\n",
        "print(f\"\\nTrain predictions sample:\")\n",
        "print(train_with_pred[[TARGET, \"predictions\"]].head())\n",
        "print(f\"\\nTest predictions sample:\")\n",
        "print(test_with_pred[[TARGET, \"predictions\"]].head())\n",
        "\n",
        "assert \"predictions\" in train_with_pred.columns\n",
        "assert \"predictions\" in test_with_pred.columns\n",
        "print(\"\\nAssertion passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuwl2aG6gYNt"
      },
      "source": [
        "## i. Test pred_auc_score:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaLl0bpHi4SD"
      },
      "source": [
        "i. Compute the train and test roc_auc metric using roc_auc_score from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJSvN4dgbA8",
        "outputId": "2843827f-e774-40e4-85b3-274f6d3b5d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 8: pred_auc_score (ROC AUC)\n",
            "============================================================\n",
            "ROC AUC (LogisticRegression):\n",
            "   Train AUC: 0.6761\n",
            "   Test AUC:  0.6559\n",
            "   Difference: 0.0202\n",
            "Model performs better than random\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Compute ROC AUC scores\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 8: pred_auc_score (ROC AUC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "auc_train = pdlib.pred_auc_score(\n",
        "    train_with_pred[TARGET],\n",
        "    train_with_pred[\"predictions\"]\n",
        ")\n",
        "auc_test = pdlib.pred_auc_score(\n",
        "    test_with_pred[TARGET],\n",
        "    test_with_pred[\"predictions\"]\n",
        ")\n",
        "\n",
        "print(f\"ROC AUC (LogisticRegression):\")\n",
        "print(f\"   Train AUC: {auc_train:.4f}\")\n",
        "print(f\"   Test AUC:  {auc_test:.4f}\")\n",
        "print(f\"   Difference: {abs(auc_train - auc_test):.4f}\")\n",
        "\n",
        "if auc_test > 0.5:\n",
        "    print(f\"Model performs better than random\")\n",
        "else:\n",
        "    print(f\"Model needs improvement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBFTrRj4gldm"
      },
      "source": [
        "## Test data_predict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzX-AnDygoGW",
        "outputId": "f224bf4c-3d3f-4c00-8336-90d3590a8546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 9: data_predict\n",
            "============================================================\n",
            "Probabilities shape: (2821,)\n",
            "   Sample: [0.31701586 0.28218064 0.11766365 0.13071773 0.33144975]\n",
            "data_predict matches add_predictions\n",
            "Class predictions: [0 0 0 0 0 0 0 0 0 0]\n",
            "   Unique classes: [np.int64(0), np.int64(1)]\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Test data_predict function\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 9: data_predict\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "# Test predict_proba\n",
        "proba_test = pdlib.data_predict(model_lr, test_df[FEATURES], proba=True)\n",
        "print(f\"Probabilities shape: {proba_test.shape}\")\n",
        "print(f\"   Sample: {proba_test[:5]}\")\n",
        "\n",
        "# Verify matches add_predictions\n",
        "assert_allclose(proba_test, test_with_pred[\"predictions\"].to_numpy(), atol=1e-9)\n",
        "print(\"data_predict matches add_predictions\")\n",
        "\n",
        "# Test class predictions\n",
        "class_pred = pdlib.data_predict(model_lr, test_df[FEATURES], proba=False)\n",
        "print(f\"Class predictions: {class_pred[:10]}\")\n",
        "print(f\"   Unique classes: {sorted(set(class_pred))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bedC6mFnnZ_A"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkgq75Zxg3ye",
        "outputId": "56af4395-ebb8-410d-cd10-9fdfd23fce3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TESTS COMPLETED SUCCESSFULLY\n",
            "============================================================\n",
            "\n",
            "Functions tested:\n",
            "   1. data_loader\n",
            "   2. data_split\n",
            "   3. data_remove_nans\n",
            "   4. data_fill_nans\n",
            "   5. data_encoding\n",
            "   6. data_binary\n",
            "   7. data_train_models\n",
            "   8. add_predictions\n",
            "   9. pred_auc_score\n",
            "  10. data_predict\n",
            "\n",
            "Final Results:\n",
            "  Dataset size: 9368 samples\n",
            "  Train: 6547 samples\n",
            "  Test:  2821 samples\n",
            "  Features: 10\n",
            "  Train AUC: 0.6761\n",
            "  Test AUC:  0.6559\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TESTS COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nFunctions tested:\")\n",
        "functions_tested = [\n",
        "    \"data_loader\", \"data_split\", \"data_remove_nans\",\n",
        "    \"data_fill_nans\", \"data_encoding\", \"data_binary\",\n",
        "    \"data_train_models\", \"add_predictions\",\n",
        "    \"pred_auc_score\", \"data_predict\"\n",
        "]\n",
        "for i, func in enumerate(functions_tested, 1):\n",
        "    print(f\"  {i:2d}. {func}\")\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  Dataset size: {len(train_with_pred) + len(test_with_pred)} samples\")\n",
        "print(f\"  Train: {len(train_with_pred)} samples\")\n",
        "print(f\"  Test:  {len(test_with_pred)} samples\")\n",
        "print(f\"  Features: {len(FEATURES)}\")\n",
        "print(f\"  Train AUC: {auc_train:.4f}\")\n",
        "print(f\"  Test AUC:  {auc_test:.4f}\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.14.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
