{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[GitHub source](https://github.com/ElvisCasco/process_data)"
      ],
      "metadata": {
        "id": "k9NZlKovcXY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "wd = '/content/drive/MyDrive/DSDM/Term_1/21DM004 Computing for Data Science/hw4/'\n",
        "from PIL import Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_KwreGVc0U9",
        "outputId": "59733eb9-0885-4bda-e290-37e1b8ed39d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rt4XV4acBNK",
        "outputId": "c847d555-39a5-4f17-f43f-7aeaf954d2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ElvisCasco/process_data.git\n",
            "  Cloning https://github.com/ElvisCasco/process_data.git to /tmp/pip-req-build-14knwtoi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ElvisCasco/process_data.git /tmp/pip-req-build-14knwtoi\n",
            "  Resolved https://github.com/ElvisCasco/process_data.git to commit 6e8ac2c234565ecc6050cad317d45cb1b2ecf42a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from process_data==0.1.0) (2.3.4)\n",
            "Requirement already satisfied: pandas>=2.3.3 in /usr/local/lib/python3.12/dist-packages (from process_data==0.1.0) (2.3.3)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.1 in /usr/local/lib/python3.12/dist-packages (from process_data==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.3->process_data==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.3->process_data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.3->process_data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.1->process_data==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.1->process_data==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.1->process_data==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.3.3->process_data==0.1.0) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ElvisCasco/process_data.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import the package (installed from GitHub)\n",
        "import process_data as pdlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import inspect\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"process_data package - Installed from GitHub\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Version: {getattr(pdlib, '__version__', 'unknown')}\")\n",
        "print(f\"Location: {pdlib.__file__}\")\n",
        "print(f\"\\nAvailable functions:\")\n",
        "exports = [n for n in dir(pdlib) if not n.startswith(\"_\")]\n",
        "for i, func in enumerate(exports, 1):\n",
        "    print(f\"  {i}. {func}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHl4g7MHcVlP",
        "outputId": "e92abfb9-cbb2-4f81-f00d-0f9d94b3e4f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "process_data package - Installed from GitHub\n",
            "============================================================\n",
            "Version: 0.1.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages/process_data/__init__.py\n",
            "\n",
            "Available functions:\n",
            "  1. data_binary\n",
            "  2. data_encoding\n",
            "  3. data_fill_nans\n",
            "  4. data_loader\n",
            "  5. data_predict\n",
            "  6. data_remove_nans\n",
            "  7. data_split\n",
            "  8. data_train_models\n",
            "  9. pred_auc_score\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a. Load the data"
      ],
      "metadata": {
        "id": "cd_Q76hzeIiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Load the data."
      ],
      "metadata": {
        "id": "eJkYuixbhNRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Prepare a sample CSV\n",
        "csv_path = wd + \"sample_diabetes_mellitus_data.csv\"\n",
        "df = pdlib.data_loader(csv_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSOtIEudhu1",
        "outputId": "ba28e271-52de-435c-ea2f-58e2402b4d93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully. Shape: (10000, 53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b. Test data_loader and data_split:"
      ],
      "metadata": {
        "id": "i1njbDQPeGCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Split the data between train and test. (you can use train_test_split from sklearn or any other way)"
      ],
      "metadata": {
        "id": "Pf4eL7rAhTof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Test data_loader and data_split\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 1: data_loader and data_split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df_loaded = pdlib.data_loader(csv_path)\n",
        "print(f\"‚úÖ data_loader: Loaded {df_loaded.shape}\")\n",
        "\n",
        "train_df, test_df = pdlib.data_split(csv_path, test_size=0.3, random_state=42)\n",
        "print(f\"‚úÖ data_split:\")\n",
        "print(f\"   Train: {train_df.shape} ({train_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")\n",
        "print(f\"   Test: {test_df.shape} ({test_df.shape[0]/df_loaded.shape[0]*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4NX-5CeSDd",
        "outputId": "62ab853f-5842-40d2-e979-620589c7aa89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 1: data_loader and data_split\n",
            "============================================================\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "‚úÖ data_loader: Loaded (10000, 53)\n",
            "Data loaded successfully. Shape: (10000, 53)\n",
            "‚úÖ data_split:\n",
            "   Train: (7000, 53) (70.0%)\n",
            "   Test: (3000, 53) (30.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c. Test data_remove_nans:"
      ],
      "metadata": {
        "id": "GUoWutD5ec-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Remove those rows that contain NaN values in the columns: age, gender, ethnicity."
      ],
      "metadata": {
        "id": "GSRnFLzLhaaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Test data_remove_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 2: data_remove_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_nan = [\"age\", \"gender\", \"ethnicity\"]\n",
        "print(f\"Before: Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "\n",
        "train_df = pdlib.data_remove_nans(train_df, columns=cols_nan)\n",
        "test_df = pdlib.data_remove_nans(test_df, columns=cols_nan)\n",
        "\n",
        "print(f\"After:  Train {train_df.shape}, NaNs={train_df[cols_nan].isna().sum().sum()}\")\n",
        "print(f\"        Test {test_df.shape}, NaNs={test_df[cols_nan].isna().sum().sum()}\")\n",
        "print(\"‚úÖ Passed: No NaNs in specified columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr_z1wjefrz",
        "outputId": "33480988-276b-4061-e326-5b38425fe504"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 2: data_remove_nans\n",
            "============================================================\n",
            "Before: Train (7000, 53), NaNs=465\n",
            "        Test (3000, 53), NaNs=185\n",
            "After:  Train (6547, 53), NaNs=0\n",
            "        Test (2821, 53), NaNs=0\n",
            "‚úÖ Passed: No NaNs in specified columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d. Test data_fill_nans:"
      ],
      "metadata": {
        "id": "pFnW6IHceptX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Fill NaN with the mean value of the column in the columns: height, weight."
      ],
      "metadata": {
        "id": "hAsmeoMzhhWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Test data_fill_nans\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 3: data_fill_nans\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cols_fill = [\"height\", \"weight\"]\n",
        "print(f\"Before: {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "\n",
        "train_df = pdlib.data_fill_nans(train_df, columns=cols_fill)\n",
        "test_df = pdlib.data_fill_nans(test_df, columns=cols_fill)\n",
        "\n",
        "print(f\"After:  {train_df[cols_fill].isna().sum().to_dict()}\")\n",
        "print(f\"‚úÖ Mean height: {train_df['height'].mean():.2f}, weight: {train_df['weight'].mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7p-jYjZetVg",
        "outputId": "41cdb3ec-28a0-44c5-f463-55da084057df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 3: data_fill_nans\n",
            "============================================================\n",
            "Before: {'height': 86, 'weight': 1077}\n",
            "After:  {'height': 0, 'weight': 0}\n",
            "‚úÖ Mean height: 169.98, weight: 86.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e. Test data_encoding:"
      ],
      "metadata": {
        "id": "-at5k0K-e3SB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Generate dummies for ethnicity column (One hot encoding)."
      ],
      "metadata": {
        "id": "6Gb-yvGFhrmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Test data_encoding (one-hot encoding)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 4: data_encoding\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: {train_df.shape[1]} columns\")\n",
        "train_df = pdlib.data_encoding(train_df, columns=[\"ethnicity\"])\n",
        "test_df = pdlib.data_encoding(test_df, columns=[\"ethnicity\"])\n",
        "\n",
        "ethnicity_cols = [c for c in train_df.columns if c.startswith(\"ethnicity_\")]\n",
        "print(f\"After:  {train_df.shape[1]} columns\")\n",
        "print(f\"‚úÖ New columns: {ethnicity_cols}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLbr2QZe6RF",
        "outputId": "a72d1e9a-7161-4e74-ebf5-190b01116a34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 4: data_encoding\n",
            "============================================================\n",
            "Before: 53 columns\n",
            "After:  58 columns\n",
            "‚úÖ New columns: ['ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## f. Test data_binary:"
      ],
      "metadata": {
        "id": "ABOWSYs1fFuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Create a binary variable for gender M/F."
      ],
      "metadata": {
        "id": "jnB3t2Hfhxw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Test data_binary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 5: data_binary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Before: gender dtype={train_df['gender'].dtype}, unique={train_df['gender'].unique()}\")\n",
        "train_df = pdlib.data_binary(train_df, column=\"gender\")\n",
        "test_df = pdlib.data_binary(test_df, column=\"gender\")\n",
        "\n",
        "print(f\"After:  gender dtype={train_df['gender'].dtype}, unique={sorted(train_df['gender'].dropna().unique())}\")\n",
        "print(f\"‚úÖ Value counts:\\n{train_df['gender'].value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LsAHrtfIcN",
        "outputId": "08d6d92e-dc50-4ed7-d219-1197f788d777"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 5: data_binary\n",
            "============================================================\n",
            "Before: gender dtype=object, unique=['F' 'M']\n",
            "After:  gender dtype=Int64, unique=[np.int64(0), np.int64(1)]\n",
            "‚úÖ Value counts:\n",
            "gender\n",
            "1    3599\n",
            "0    2948\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## g. Test data_train_models:"
      ],
      "metadata": {
        "id": "gR9Uw4GXf2la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "g. Train a model (for instance LogisticRegression or RandomForestClassifier from sklearn) in the train data.\n",
        "\n",
        "Use as features the columns: `age`, `height`, `weight`, `aids`, `cirrhosis`, `hepatic_failure`, `immunosuppression`, `leukemia`, `lymphoma`, `solid_tumor_with_metastasis`.\n",
        "\n",
        "Use as target the column: `diabetes_mellitus`"
      ],
      "metadata": {
        "id": "hXPmlHuHiA7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Train models\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 6: data_train_models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "FEATURES = [\n",
        "    \"age\", \"height\", \"weight\",\n",
        "    \"aids\", \"cirrhosis\", \"hepatic_failure\",\n",
        "    \"immunosuppression\", \"leukemia\", \"lymphoma\",\n",
        "    \"solid_tumor_with_metastasis\",\n",
        "]\n",
        "TARGET = \"diabetes_mellitus\"\n",
        "\n",
        "X_train = train_df[FEATURES]\n",
        "y_train = train_df[TARGET]\n",
        "\n",
        "print(f\"Training with {len(FEATURES)} features, {len(X_train)} samples\")\n",
        "model_lr = pdlib.data_train_models(X_train, y_train, model_type=\"logreg\")\n",
        "model_rf = pdlib.data_train_models(X_train, y_train, model_type=\"rf\")\n",
        "\n",
        "print(f\"‚úÖ Trained: {type(model_lr).__name__}\")\n",
        "print(f\"‚úÖ Trained: {type(model_rf).__name__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92JAivSXf50G",
        "outputId": "21aec3f0-2a7b-412b-92b9-dffd090206c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 6: data_train_models\n",
            "============================================================\n",
            "Training with 10 features, 6547 samples\n",
            "‚úÖ Trained: LogisticRegression\n",
            "‚úÖ Trained: RandomForestClassifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## h. Test add_predictions:"
      ],
      "metadata": {
        "id": "iBDdiKUDgI9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "h. Predict the targets for both the train and test sets and add the prediction as a new column (use predict_proba from the model to get the predicted probabilities) name the new column something\n",
        "like predictions."
      ],
      "metadata": {
        "id": "_C3kzsGhieiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Add predictions to train and test sets\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 7: add_predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Import add_predictions function\n",
        "try:\n",
        "    add_predictions = pdlib.add_predictions\n",
        "except AttributeError:\n",
        "    from process_data.pred_auc_score import add_predictions\n",
        "\n",
        "# Add predictions using LogisticRegression model\n",
        "train_with_pred, test_with_pred = add_predictions(\n",
        "    model_lr,\n",
        "    train_df,\n",
        "    test_df,\n",
        "    FEATURES,\n",
        "    pred_col=\"predictions\",\n",
        "    inplace=False\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Added 'predictions' column to train and test sets\")\n",
        "print(f\"\\nüìä Train predictions sample:\")\n",
        "print(train_with_pred[[TARGET, \"predictions\"]].head())\n",
        "print(f\"\\nüìä Test predictions sample:\")\n",
        "print(test_with_pred[[TARGET, \"predictions\"]].head())\n",
        "\n",
        "assert \"predictions\" in train_with_pred.columns\n",
        "assert \"predictions\" in test_with_pred.columns\n",
        "print(\"\\n‚úÖ Assertion passed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiOkg5HvgLXg",
        "outputId": "34c37954-db6e-42d5-bcde-6101acccdcbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 7: add_predictions\n",
            "============================================================\n",
            "‚úÖ Added 'predictions' column to train and test sets\n",
            "\n",
            "üìä Train predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "9069                  0     0.133019\n",
            "2603                  0     0.235128\n",
            "7738                  0     0.305615\n",
            "1579                  0     0.168840\n",
            "5058                  0     0.156941\n",
            "\n",
            "üìä Test predictions sample:\n",
            "      diabetes_mellitus  predictions\n",
            "6252                  1     0.317018\n",
            "1731                  0     0.282180\n",
            "4742                  0     0.117651\n",
            "4521                  0     0.130718\n",
            "6340                  1     0.331449\n",
            "\n",
            "‚úÖ Assertion passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## i. Test pred_auc_score:"
      ],
      "metadata": {
        "id": "Nuwl2aG6gYNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i. Compute the train and test roc_auc metric using roc_auc_score from sklearn."
      ],
      "metadata": {
        "id": "qaLl0bpHi4SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Compute ROC AUC scores\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 8: pred_auc_score (ROC AUC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "auc_train = pdlib.pred_auc_score(\n",
        "    train_with_pred[TARGET],\n",
        "    train_with_pred[\"predictions\"]\n",
        ")\n",
        "auc_test = pdlib.pred_auc_score(\n",
        "    test_with_pred[TARGET],\n",
        "    test_with_pred[\"predictions\"]\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ ROC AUC (LogisticRegression):\")\n",
        "print(f\"   Train AUC: {auc_train:.4f}\")\n",
        "print(f\"   Test AUC:  {auc_test:.4f}\")\n",
        "print(f\"   Difference: {abs(auc_train - auc_test):.4f}\")\n",
        "\n",
        "if auc_test > 0.5:\n",
        "    print(f\"‚úÖ Model performs better than random\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Model needs improvement\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJSvN4dgbA8",
        "outputId": "2843827f-e774-40e4-85b3-274f6d3b5d50"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 8: pred_auc_score (ROC AUC)\n",
            "============================================================\n",
            "‚úÖ ROC AUC (LogisticRegression):\n",
            "   Train AUC: 0.6761\n",
            "   Test AUC:  0.6559\n",
            "   Difference: 0.0202\n",
            "‚úÖ Model performs better than random\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test data_predict:"
      ],
      "metadata": {
        "id": "uBFTrRj4gldm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Test data_predict function\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST 9: data_predict\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "# Test predict_proba\n",
        "proba_test = pdlib.data_predict(model_lr, test_df[FEATURES], proba=True)\n",
        "print(f\"‚úÖ Probabilities shape: {proba_test.shape}\")\n",
        "print(f\"   Sample: {proba_test[:5]}\")\n",
        "\n",
        "# Verify matches add_predictions\n",
        "assert_allclose(proba_test, test_with_pred[\"predictions\"].to_numpy(), atol=1e-9)\n",
        "print(\"‚úÖ data_predict matches add_predictions\")\n",
        "\n",
        "# Test class predictions\n",
        "class_pred = pdlib.data_predict(model_lr, test_df[FEATURES], proba=False)\n",
        "print(f\"‚úÖ Class predictions: {class_pred[:10]}\")\n",
        "print(f\"   Unique classes: {sorted(set(class_pred))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzX-AnDygoGW",
        "outputId": "f224bf4c-3d3f-4c00-8336-90d3590a8546"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TEST 9: data_predict\n",
            "============================================================\n",
            "‚úÖ Probabilities shape: (2821,)\n",
            "   Sample: [0.31701752 0.28218009 0.1176509  0.13071842 0.33144866]\n",
            "‚úÖ data_predict matches add_predictions\n",
            "‚úÖ Class predictions: [0 0 0 0 0 0 0 0 0 0]\n",
            "   Unique classes: [np.int64(0), np.int64(1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "bedC6mFnnZ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéâ ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n‚úÖ Functions tested:\")\n",
        "functions_tested = [\n",
        "    \"data_loader\", \"data_split\", \"data_remove_nans\",\n",
        "    \"data_fill_nans\", \"data_encoding\", \"data_binary\",\n",
        "    \"data_train_models\", \"add_predictions\",\n",
        "    \"pred_auc_score\", \"data_predict\"\n",
        "]\n",
        "for i, func in enumerate(functions_tested, 1):\n",
        "    print(f\"  {i:2d}. {func}\")\n",
        "\n",
        "print(f\"\\nüìä Final Results:\")\n",
        "print(f\"  Dataset size: {len(train_with_pred) + len(test_with_pred)} samples\")\n",
        "print(f\"  Train: {len(train_with_pred)} samples\")\n",
        "print(f\"  Test:  {len(test_with_pred)} samples\")\n",
        "print(f\"  Features: {len(FEATURES)}\")\n",
        "print(f\"  Train AUC: {auc_train:.4f}\")\n",
        "print(f\"  Test AUC:  {auc_test:.4f}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkgq75Zxg3ye",
        "outputId": "56af4395-ebb8-410d-cd10-9fdfd23fce3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üéâ ALL TESTS COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "\n",
            "‚úÖ Functions tested:\n",
            "   1. data_loader\n",
            "   2. data_split\n",
            "   3. data_remove_nans\n",
            "   4. data_fill_nans\n",
            "   5. data_encoding\n",
            "   6. data_binary\n",
            "   7. data_train_models\n",
            "   8. add_predictions\n",
            "   9. pred_auc_score\n",
            "  10. data_predict\n",
            "\n",
            "üìä Final Results:\n",
            "  Dataset size: 9368 samples\n",
            "  Train: 6547 samples\n",
            "  Test:  2821 samples\n",
            "  Features: 10\n",
            "  Train AUC: 0.6761\n",
            "  Test AUC:  0.6559\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}